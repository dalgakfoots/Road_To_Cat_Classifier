{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cat and Dog Classifier Add train(AlexNet) 2nd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNvZrfTJfND0"
      },
      "source": [
        "import tensorflow\r\n",
        "import keras\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_hooHQvfWSQ"
      },
      "source": [
        "train_dir = '/content/drive/MyDrive/CatClassifier/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNIQGIRugMr_"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\r\n",
        "    validation_split=0.2,\r\n",
        "    rescale=1./255,\r\n",
        "    shear_range=0.1,\r\n",
        "    zoom_range=0.2,\r\n",
        "    horizontal_flip=True,\r\n",
        "    width_shift_range=0.1,\r\n",
        "    height_shift_range=0.1,\r\n",
        "    rotation_range=15,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZObHhqGfXev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d416891-5ca7-4195-a347-fb91891ef822"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\r\n",
        "    train_dir,\r\n",
        "    target_size=(227,227),\r\n",
        "    batch_size=32,\r\n",
        "    subset='training',\r\n",
        "    class_mode='binary',\r\n",
        ")\r\n",
        "\r\n",
        "validation_generator = train_datagen.flow_from_directory(\r\n",
        "    train_dir,\r\n",
        "    target_size=(227,227),\r\n",
        "    batch_size=32,\r\n",
        "    subset='validation',\r\n",
        "    class_mode='binary'\r\n",
        ")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20001 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq0kuK2Ysbfz"
      },
      "source": [
        "# 추가 학습을 위해 미리 저장한 모델을 불러옴\r\n",
        "additional_model = keras.models.load_model('/content/drive/MyDrive/CatClassifier/AlexNet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTaI9ismsmJx",
        "outputId": "dd0b40ab-e322-437a-af0c-0b332595176c"
      },
      "source": [
        "additional_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 55, 55, 96)        34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 55, 55, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 27, 27, 256)       614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 27, 27, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 13, 13, 384)       885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 13, 13, 384)       1536      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 13, 13, 384)       1536      \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 13, 13, 256)       884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 13, 13, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4096)              37752832  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 58,295,042\n",
            "Trainable params: 58,292,290\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeqtzQQmh73W"
      },
      "source": [
        "additional_model.compile(loss='sparse_categorical_crossentropy',\r\n",
        "              optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9, decay = 0.0005),\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Rb72syrIfr"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ3kYBdJteRa"
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/CatClassifier/AlexNet',\r\n",
        "                             monitor='val_accuracy',\r\n",
        "                             verbose=1,\r\n",
        "                             save_best_only=True,\r\n",
        "                             save_weights_only=False,\r\n",
        "                             mode='auto',)\r\n",
        "\r\n",
        "early = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience = 5, verbose = 1, mode= 'auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNvqdjN7fyX-",
        "outputId": "5951ba4f-5a6e-44eb-ec3e-9e4595de04bf"
      },
      "source": [
        "num_train_samples = train_generator.n\r\n",
        "num_train_batches = train_generator.batch_size\r\n",
        "print(num_train_samples,' , ',num_train_batches)\r\n",
        "train_size = num_train_samples // num_train_batches\r\n",
        "print(train_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20001  ,  32\n",
            "625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ByIUghxg8jn",
        "outputId": "2aa4d0ba-f255-497e-d8f0-85e4cded3aae"
      },
      "source": [
        "num_val_samples = validation_generator.n\r\n",
        "num_val_batches = validation_generator.batch_size\r\n",
        "print(num_val_samples,' , ',num_val_batches)\r\n",
        "val_size = num_val_samples // num_val_batches\r\n",
        "print(val_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000  ,  32\n",
            "156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_0pKkUoiPQX",
        "outputId": "42e94ed2-bdb7-492a-bc27-c29e2e1233c0"
      },
      "source": [
        "hist = additional_model.fit(train_generator,\r\n",
        "                 steps_per_epoch=train_size, \r\n",
        "                 epochs = 100 , \r\n",
        "                 validation_data=validation_generator ,\r\n",
        "                 validation_steps=val_size ,\r\n",
        "                 verbose=1,\r\n",
        "                 callbacks=[checkpoint, early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "625/625 [==============================] - 15968s 26s/step - loss: 0.4299 - accuracy: 0.8045 - val_loss: 0.6174 - val_accuracy: 0.6867\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.68670, saving model to /content/drive/MyDrive/CatClassifier/AlexNet\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CatClassifier/AlexNet/assets\n",
            "Epoch 2/100\n",
            "625/625 [==============================] - 380s 608ms/step - loss: 0.4094 - accuracy: 0.8140 - val_loss: 0.6853 - val_accuracy: 0.6550\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.68670\n",
            "Epoch 3/100\n",
            "625/625 [==============================] - 378s 605ms/step - loss: 0.3633 - accuracy: 0.8350 - val_loss: 0.3668 - val_accuracy: 0.8359\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.68670 to 0.83594, saving model to /content/drive/MyDrive/CatClassifier/AlexNet\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CatClassifier/AlexNet/assets\n",
            "Epoch 4/100\n",
            "625/625 [==============================] - 368s 590ms/step - loss: 0.3440 - accuracy: 0.8457 - val_loss: 0.3435 - val_accuracy: 0.8488\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.83594 to 0.84876, saving model to /content/drive/MyDrive/CatClassifier/AlexNet\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CatClassifier/AlexNet/assets\n",
            "Epoch 5/100\n",
            "625/625 [==============================] - 366s 586ms/step - loss: 0.3166 - accuracy: 0.8593 - val_loss: 0.3621 - val_accuracy: 0.8341\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.84876\n",
            "Epoch 6/100\n",
            "625/625 [==============================] - 366s 586ms/step - loss: 0.2938 - accuracy: 0.8706 - val_loss: 0.4417 - val_accuracy: 0.7979\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.84876\n",
            "Epoch 7/100\n",
            "625/625 [==============================] - 371s 595ms/step - loss: 0.2906 - accuracy: 0.8767 - val_loss: 0.3137 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.84876 to 0.85978, saving model to /content/drive/MyDrive/CatClassifier/AlexNet\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CatClassifier/AlexNet/assets\n",
            "Epoch 8/100\n",
            "625/625 [==============================] - 377s 603ms/step - loss: 0.2672 - accuracy: 0.8855 - val_loss: 0.3058 - val_accuracy: 0.8666\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.85978 to 0.86659, saving model to /content/drive/MyDrive/CatClassifier/AlexNet\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CatClassifier/AlexNet/assets\n",
            "Epoch 9/100\n",
            "625/625 [==============================] - 381s 610ms/step - loss: 0.2648 - accuracy: 0.8862 - val_loss: 0.2900 - val_accuracy: 0.8730\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.86659 to 0.87300, saving model to /content/drive/MyDrive/CatClassifier/AlexNet\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CatClassifier/AlexNet/assets\n",
            "Epoch 10/100\n",
            "625/625 [==============================] - 378s 606ms/step - loss: 0.2539 - accuracy: 0.8896 - val_loss: 0.3636 - val_accuracy: 0.8399\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.87300\n",
            "Epoch 11/100\n",
            "625/625 [==============================] - 378s 605ms/step - loss: 0.2529 - accuracy: 0.8939 - val_loss: 0.7343 - val_accuracy: 0.7047\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.87300\n",
            "Epoch 12/100\n",
            "625/625 [==============================] - 380s 609ms/step - loss: 0.2473 - accuracy: 0.8973 - val_loss: 0.3149 - val_accuracy: 0.8614\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.87300\n",
            "Epoch 13/100\n",
            "625/625 [==============================] - 378s 606ms/step - loss: 0.2364 - accuracy: 0.9000 - val_loss: 0.2473 - val_accuracy: 0.8980\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.87300 to 0.89804, saving model to /content/drive/MyDrive/CatClassifier/AlexNet\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CatClassifier/AlexNet/assets\n",
            "Epoch 14/100\n",
            "625/625 [==============================] - 382s 611ms/step - loss: 0.2249 - accuracy: 0.9045 - val_loss: 0.3836 - val_accuracy: 0.8355\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.89804\n",
            "Epoch 15/100\n",
            "625/625 [==============================] - 380s 609ms/step - loss: 0.2148 - accuracy: 0.9081 - val_loss: 0.2533 - val_accuracy: 0.8952\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.89804\n",
            "Epoch 16/100\n",
            "625/625 [==============================] - 380s 608ms/step - loss: 0.2066 - accuracy: 0.9126 - val_loss: 0.2725 - val_accuracy: 0.8834\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.89804\n",
            "Epoch 17/100\n",
            "625/625 [==============================] - 377s 604ms/step - loss: 0.2138 - accuracy: 0.9076 - val_loss: 0.3200 - val_accuracy: 0.8656\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.89804\n",
            "Epoch 18/100\n",
            "625/625 [==============================] - 378s 605ms/step - loss: 0.2076 - accuracy: 0.9132 - val_loss: 0.2805 - val_accuracy: 0.8854\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.89804\n",
            "Epoch 00018: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A4zj20UFzCZ",
        "outputId": "564ab8bf-655e-483f-faa1-af4d5996edcc"
      },
      "source": [
        "additional_model.evaluate(train_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "626/626 [==============================] - 304s 485ms/step - loss: 0.2151 - accuracy: 0.9095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21505282819271088, 0.9095045328140259]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMmWf9lYjIWN",
        "outputId": "8b4f206d-44e0-4342-a180-e49404123c14"
      },
      "source": [
        "additional_model.save('/content/drive/MyDrive/CatClassifier/AlexNet/additional train (2)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CatClassifier/AlexNet/additional train (2)/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBQrW8NFSJpC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}